# coding: utf-8
"""
    Snowflake Schema API.

    The Snowflake Schema API is a REST API that you can use to access, update, and perform certain actions on a Snowflake schema.  # noqa: E501

    The version of the OpenAPI document: 0.0.1
    Contact: support@snowflake.com
    Generated by: https://openapi-generator.tech

    Do not edit this file manually.
"""

from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from typing import Union

from snowflake.core.schema._generated.models.point_of_time import PointOfTime

from datetime import datetime

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator

from typing import Any, ClassVar, Dict, List, Optional

from typing_extensions import Annotated


class SchemaClone(BaseModel):
    """A model object representing the SchemaClone resource.

    Constructs an object of type SchemaClone with the provided properties.

    Parameters
    __________
    name : str
        A Snowflake object identifier. If the identifier contains spaces or special characters, the entire string must be enclosed in double quotes. Identifiers enclosed in double quotes are also case-sensitive.
    point_of_time : PointOfTime, optional

    created_on : datetime, optional
        Date and time the schema was created.
    kind : str,  default 'PERMANENT'
        Schema type, permanent (default) or transient.
    is_default : bool, optional
        Default schema for a user.
    is_current : bool, optional
        Current schema for the session.
    database_name : str, optional
        Database that the schema belongs to
    owner : str, optional
        Name of the role that owns the schema.
    comment : str, optional
        Optional comment in which to store information related to the schema.
    options : str, optional

    managed_access : bool,  default False
        Whether this schema is a managed access schema that centralizes privilege management with the schema owner.
    retention_time : int, optional
        Number of days that historical data is retained for Time Travel.
    dropped_on : datetime, optional
        Date and time the schema was dropped.
    owner_role_type : str, optional
        Type of role that owns the object, either `ROLE` or `DATABASE_ROLE`.
    budget : str, optional
        Budget that defines a monthly spending limit on the compute costs  for a Snowflake account or a custom group of Snowflake objects.
    data_retention_time_in_days : int, optional
        Number of days for which Time Travel actions (CLONE and UNDROP) can be performed on the schema, as well as specifying the default Time Travel retention time for all tables created in the schema
    default_ddl_collation : str, optional
        Specifies a default collation specification for all tables added to the schema. You an override the default at the schema and individual table levels.
    log_level : str, optional
        Severity level of messages that should be ingested and made available in the active event table. Currently, Snowflake supports only `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, `FATAL` and `OFF`.
    pipe_execution_paused : bool, optional
        Whether pipe execution is paused.
    max_data_extension_time_in_days : int, optional
        Maximum number of days for which Snowflake can extend the data retention period for tables in the schema to prevent streams on the tables from becoming stale.
    suspend_task_after_num_failures : int, optional
        Specifies the number of consecutive failed task runs after which the current task is suspended automatically.
    trace_level : str, optional
        How trace events are ingested into the event table. Currently, Snowflake supports only `ALWAYS`, `ON_EVENT`, and `OFF`.
    user_task_managed_initial_warehouse_size : str, optional
        Size of the compute resources to provision for the first run of the serverless task, before a task history is available for Snowflake to determine an ideal size.
    user_task_timeout_ms : int, optional
        Time limit, in milliseconds, for a single run of the task before it times out.
    serverless_task_min_statement_size : str, optional
        Specifies the minimum allowed warehouse size for the serverless task. Minimum XSMALL, Maximum XXLARGE.
    serverless_task_max_statement_size : str, optional
        Specifies the maximum allowed warehouse size for the serverless task. Minimum XSMALL, Maximum XXLARGE.
    """

    point_of_time: Optional[PointOfTime] = None

    created_on: Optional[datetime] = None

    name: Annotated[str, Field(strict=True)]

    kind: Optional[StrictStr] = 'PERMANENT'

    is_default: Optional[StrictBool] = None

    is_current: Optional[StrictBool] = None

    database_name: Optional[StrictStr] = None

    owner: Optional[StrictStr] = None

    comment: Optional[StrictStr] = None

    options: Optional[StrictStr] = None

    managed_access: Optional[StrictBool] = False

    retention_time: Optional[StrictInt] = None

    dropped_on: Optional[datetime] = None

    owner_role_type: Optional[StrictStr] = None

    budget: Optional[StrictStr] = None

    data_retention_time_in_days: Optional[StrictInt] = None

    default_ddl_collation: Optional[StrictStr] = None

    log_level: Optional[StrictStr] = None

    pipe_execution_paused: Optional[StrictBool] = None

    max_data_extension_time_in_days: Optional[StrictInt] = None

    suspend_task_after_num_failures: Optional[StrictInt] = None

    trace_level: Optional[StrictStr] = None

    user_task_managed_initial_warehouse_size: Optional[StrictStr] = None

    user_task_timeout_ms: Optional[StrictInt] = None

    serverless_task_min_statement_size: Optional[StrictStr] = None

    serverless_task_max_statement_size: Optional[StrictStr] = None

    __properties = [
        "created_on", "name", "kind", "is_default", "is_current",
        "database_name", "owner", "comment", "options", "managed_access",
        "retention_time", "dropped_on", "owner_role_type", "budget",
        "data_retention_time_in_days", "default_ddl_collation", "log_level",
        "pipe_execution_paused", "max_data_extension_time_in_days",
        "suspend_task_after_num_failures", "trace_level",
        "user_task_managed_initial_warehouse_size", "user_task_timeout_ms",
        "serverless_task_min_statement_size",
        "serverless_task_max_statement_size"
    ]

    @field_validator('name')
    def name_validate_regular_expression(cls, v):

        if not re.match(r"""^\"([^\"]|\"\")+\"|[a-zA-Z_][a-zA-Z0-9_$]*$""", v):
            raise ValueError(
                r"""must validate the regular expression /^"([^"]|"")+"|[a-zA-Z_][a-zA-Z0-9_$]*$/"""
            )
        return v

    @field_validator('kind')
    def kind_validate_enum(cls, v):

        if v is None:
            return v
        if v not in ('PERMANENT', 'TRANSIENT'):
            raise ValueError(
                "must validate the enum values ('PERMANENT','TRANSIENT')")
        return v

    class Config:
        populate_by_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias."""
        return pprint.pformat(self.dict(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias."""
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> SchemaClone:
        """Create an instance of SchemaClone from a JSON string."""
        return cls.from_dict(json.loads(json_str))

    def to_dict(
        self,
        hide_readonly_properties: bool = False,
    ) -> dict[str, Any]:
        """Returns the dictionary representation of the model using alias."""

        exclude_properties = set()

        if hide_readonly_properties:
            exclude_properties.update({
                "created_on",
                "is_default",
                "is_current",
                "database_name",
                "owner",
                "options",
                "retention_time",
                "dropped_on",
                "owner_role_type",
                "budget",
            })

        _dict = dict(
            self._iter(to_dict=True,
                       by_alias=True,
                       exclude=exclude_properties,
                       exclude_none=True))

        # override the default output from pydantic by calling `to_dict()` of point_of_time
        if self.point_of_time:
            _dict['point_of_time'] = self.point_of_time.to_dict()

        # set to None if dropped_on (nullable) is None
        if self.dropped_on is None:
            _dict['dropped_on'] = None

        return _dict

    def to_dict_without_readonly_properties(self) -> dict[str, Any]:
        """Return the dictionary representation of the model without readonly properties."""
        return self.to_dict(hide_readonly_properties=True)

    @classmethod
    def from_dict(cls, obj: dict) -> SchemaClone:
        """Create an instance of SchemaClone from a dict."""

        if obj is None:
            return None

        if type(obj) is not dict:
            return SchemaClone.parse_obj(obj)

        _obj = SchemaClone.parse_obj({
            "point_of_time":
            PointOfTime.from_dict(obj.get("point_of_time"))
            if obj.get("point_of_time") is not None else None,
            "created_on":
            obj.get("created_on"),
            "name":
            obj.get("name"),
            "kind":
            obj.get("kind") if obj.get("kind") is not None else 'PERMANENT',
            "is_default":
            obj.get("is_default"),
            "is_current":
            obj.get("is_current"),
            "database_name":
            obj.get("database_name"),
            "owner":
            obj.get("owner"),
            "comment":
            obj.get("comment"),
            "options":
            obj.get("options"),
            "managed_access":
            obj.get("managed_access")
            if obj.get("managed_access") is not None else False,
            "retention_time":
            obj.get("retention_time"),
            "dropped_on":
            obj.get("dropped_on"),
            "owner_role_type":
            obj.get("owner_role_type"),
            "budget":
            obj.get("budget"),
            "data_retention_time_in_days":
            obj.get("data_retention_time_in_days"),
            "default_ddl_collation":
            obj.get("default_ddl_collation"),
            "log_level":
            obj.get("log_level"),
            "pipe_execution_paused":
            obj.get("pipe_execution_paused"),
            "max_data_extension_time_in_days":
            obj.get("max_data_extension_time_in_days"),
            "suspend_task_after_num_failures":
            obj.get("suspend_task_after_num_failures"),
            "trace_level":
            obj.get("trace_level"),
            "user_task_managed_initial_warehouse_size":
            obj.get("user_task_managed_initial_warehouse_size"),
            "user_task_timeout_ms":
            obj.get("user_task_timeout_ms"),
            "serverless_task_min_statement_size":
            obj.get("serverless_task_min_statement_size"),
            "serverless_task_max_statement_size":
            obj.get("serverless_task_max_statement_size"),
        })

        return _obj


from typing import Optional, List, Dict

from snowflake.core.schema._generated.models.point_of_time import PointOfTime


class SchemaCloneModel():

    def __init__(
        self,
        name: str,
        # optional properties
        point_of_time: Optional[PointOfTime] = None,
        created_on: Optional[datetime] = None,
        kind: Optional[str] = 'PERMANENT',
        is_default: Optional[bool] = None,
        is_current: Optional[bool] = None,
        database_name: Optional[str] = None,
        owner: Optional[str] = None,
        comment: Optional[str] = None,
        options: Optional[str] = None,
        managed_access: Optional[bool] = False,
        retention_time: Optional[int] = None,
        dropped_on: Optional[datetime] = None,
        owner_role_type: Optional[str] = None,
        budget: Optional[str] = None,
        data_retention_time_in_days: Optional[int] = None,
        default_ddl_collation: Optional[str] = None,
        log_level: Optional[str] = None,
        pipe_execution_paused: Optional[bool] = None,
        max_data_extension_time_in_days: Optional[int] = None,
        suspend_task_after_num_failures: Optional[int] = None,
        trace_level: Optional[str] = None,
        user_task_managed_initial_warehouse_size: Optional[str] = None,
        user_task_timeout_ms: Optional[int] = None,
        serverless_task_min_statement_size: Optional[str] = None,
        serverless_task_max_statement_size: Optional[str] = None,
    ):
        """A model object representing the SchemaClone resource.

        Constructs an object of type SchemaClone with the provided properties.

        Parameters
        __________
        name : str
            A Snowflake object identifier. If the identifier contains spaces or special characters, the entire string must be enclosed in double quotes. Identifiers enclosed in double quotes are also case-sensitive.
        point_of_time : PointOfTime, optional

        created_on : datetime, optional
            Date and time the schema was created.
        kind : str,  default 'PERMANENT'
            Schema type, permanent (default) or transient.
        is_default : bool, optional
            Default schema for a user.
        is_current : bool, optional
            Current schema for the session.
        database_name : str, optional
            Database that the schema belongs to
        owner : str, optional
            Name of the role that owns the schema.
        comment : str, optional
            Optional comment in which to store information related to the schema.
        options : str, optional

        managed_access : bool,  default False
            Whether this schema is a managed access schema that centralizes privilege management with the schema owner.
        retention_time : int, optional
            Number of days that historical data is retained for Time Travel.
        dropped_on : datetime, optional
            Date and time the schema was dropped.
        owner_role_type : str, optional
            Type of role that owns the object, either `ROLE` or `DATABASE_ROLE`.
        budget : str, optional
            Budget that defines a monthly spending limit on the compute costs  for a Snowflake account or a custom group of Snowflake objects.
        data_retention_time_in_days : int, optional
            Number of days for which Time Travel actions (CLONE and UNDROP) can be performed on the schema, as well as specifying the default Time Travel retention time for all tables created in the schema
        default_ddl_collation : str, optional
            Specifies a default collation specification for all tables added to the schema. You an override the default at the schema and individual table levels.
        log_level : str, optional
            Severity level of messages that should be ingested and made available in the active event table. Currently, Snowflake supports only `TRACE`, `DEBUG`, `INFO`, `WARN`, `ERROR`, `FATAL` and `OFF`.
        pipe_execution_paused : bool, optional
            Whether pipe execution is paused.
        max_data_extension_time_in_days : int, optional
            Maximum number of days for which Snowflake can extend the data retention period for tables in the schema to prevent streams on the tables from becoming stale.
        suspend_task_after_num_failures : int, optional
            Specifies the number of consecutive failed task runs after which the current task is suspended automatically.
        trace_level : str, optional
            How trace events are ingested into the event table. Currently, Snowflake supports only `ALWAYS`, `ON_EVENT`, and `OFF`.
        user_task_managed_initial_warehouse_size : str, optional
            Size of the compute resources to provision for the first run of the serverless task, before a task history is available for Snowflake to determine an ideal size.
        user_task_timeout_ms : int, optional
            Time limit, in milliseconds, for a single run of the task before it times out.
        serverless_task_min_statement_size : str, optional
            Specifies the minimum allowed warehouse size for the serverless task. Minimum XSMALL, Maximum XXLARGE.
        serverless_task_max_statement_size : str, optional
            Specifies the maximum allowed warehouse size for the serverless task. Minimum XSMALL, Maximum XXLARGE.
        """

        self.point_of_time = point_of_time
        self.created_on = created_on
        self.name = name
        self.kind = kind
        self.is_default = is_default
        self.is_current = is_current
        self.database_name = database_name
        self.owner = owner
        self.comment = comment
        self.options = options
        self.managed_access = managed_access
        self.retention_time = retention_time
        self.dropped_on = dropped_on
        self.owner_role_type = owner_role_type
        self.budget = budget
        self.data_retention_time_in_days = data_retention_time_in_days
        self.default_ddl_collation = default_ddl_collation
        self.log_level = log_level
        self.pipe_execution_paused = pipe_execution_paused
        self.max_data_extension_time_in_days = max_data_extension_time_in_days
        self.suspend_task_after_num_failures = suspend_task_after_num_failures
        self.trace_level = trace_level
        self.user_task_managed_initial_warehouse_size = user_task_managed_initial_warehouse_size
        self.user_task_timeout_ms = user_task_timeout_ms
        self.serverless_task_min_statement_size = serverless_task_min_statement_size
        self.serverless_task_max_statement_size = serverless_task_max_statement_size

    __properties = [
        "created_on", "name", "kind", "is_default", "is_current",
        "database_name", "owner", "comment", "options", "managed_access",
        "retention_time", "dropped_on", "owner_role_type", "budget",
        "data_retention_time_in_days", "default_ddl_collation", "log_level",
        "pipe_execution_paused", "max_data_extension_time_in_days",
        "suspend_task_after_num_failures", "trace_level",
        "user_task_managed_initial_warehouse_size", "user_task_timeout_ms",
        "serverless_task_min_statement_size",
        "serverless_task_max_statement_size"
    ]

    def __repr__(self) -> str:
        return repr(self._to_model())

    def _to_model(self):
        return SchemaClone(
            point_of_time=self.point_of_time._to_model()
            if self.point_of_time is not None else None,
            created_on=self.created_on,
            name=self.name,
            kind=self.kind,
            is_default=self.is_default,
            is_current=self.is_current,
            database_name=self.database_name,
            owner=self.owner,
            comment=self.comment,
            options=self.options,
            managed_access=self.managed_access,
            retention_time=self.retention_time,
            dropped_on=self.dropped_on,
            owner_role_type=self.owner_role_type,
            budget=self.budget,
            data_retention_time_in_days=self.data_retention_time_in_days,
            default_ddl_collation=self.default_ddl_collation,
            log_level=self.log_level,
            pipe_execution_paused=self.pipe_execution_paused,
            max_data_extension_time_in_days=self.
            max_data_extension_time_in_days,
            suspend_task_after_num_failures=self.
            suspend_task_after_num_failures,
            trace_level=self.trace_level,
            user_task_managed_initial_warehouse_size=self.
            user_task_managed_initial_warehouse_size,
            user_task_timeout_ms=self.user_task_timeout_ms,
            serverless_task_min_statement_size=self.
            serverless_task_min_statement_size,
            serverless_task_max_statement_size=self.
            serverless_task_max_statement_size,
        )

    @classmethod
    def _from_model(cls, model) -> SchemaCloneModel:
        return SchemaCloneModel(
            point_of_time=PointOfTimeModel._from_model(model.point_of_time)
            if model.point_of_time is not None else None,
            created_on=model.created_on,
            name=model.name,
            kind=model.kind,
            is_default=model.is_default,
            is_current=model.is_current,
            database_name=model.database_name,
            owner=model.owner,
            comment=model.comment,
            options=model.options,
            managed_access=model.managed_access,
            retention_time=model.retention_time,
            dropped_on=model.dropped_on,
            owner_role_type=model.owner_role_type,
            budget=model.budget,
            data_retention_time_in_days=model.data_retention_time_in_days,
            default_ddl_collation=model.default_ddl_collation,
            log_level=model.log_level,
            pipe_execution_paused=model.pipe_execution_paused,
            max_data_extension_time_in_days=model.
            max_data_extension_time_in_days,
            suspend_task_after_num_failures=model.
            suspend_task_after_num_failures,
            trace_level=model.trace_level,
            user_task_managed_initial_warehouse_size=model.
            user_task_managed_initial_warehouse_size,
            user_task_timeout_ms=model.user_task_timeout_ms,
            serverless_task_min_statement_size=model.
            serverless_task_min_statement_size,
            serverless_task_max_statement_size=model.
            serverless_task_max_statement_size,
        )

    def to_dict(self):
        """Creates a dictionary of the properties from a SchemaClone.

        This method constructs a dictionary with the key-value entries corresponding to the properties of the SchemaClone object.

        Returns
        _______
        dict
            A dictionary object created using the input model.
        """
        return self._to_model().to_dict()

    @classmethod
    def from_dict(cls, obj: dict) -> SchemaCloneModel:
        """Creates an instance of SchemaClone from a dict.

        This method constructs a SchemaClone object from a dictionary with the key-value pairs of its properties.

        Parameters
        ----------
        obj : dict
            A dictionary whose keys and values correspond to the properties of the resource object.

        Returns
        _______
        SchemaClone
            A SchemaClone object created using the input dictionary; this will fail if the required properties are missing.
        """
        return cls._from_model(SchemaClone.from_dict(obj))


SchemaClone._model_class = SchemaCloneModel
